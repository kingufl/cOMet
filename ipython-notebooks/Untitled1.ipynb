{
 "metadata": {
  "name": "",
  "signature": "sha256:a2b32b175652a8ab5906586e1bceb848868ec5bbea19bc09814fbffcf4f0a71c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Bio\n",
      "import Bio.Restriction\n",
      "import Bio.SeqIO\n",
      "import Bio.SearchIO\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib64/python2.7/site-packages/Bio/SearchIO/__init__.py:211: BiopythonExperimentalWarning: Bio.SearchIO is an experimental submodule which may undergo significant changes prior to its future official release.\n",
        "  BiopythonExperimentalWarning)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ref_genome = \"/s/fir/a/nobackup/data/ECOLI_Reference_Genome/ecoli.fa\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"/s/fir/a/nobackup/data/ECOLI_Reference_Genome/ecoli.fa\", \"rU\") as ref_handle:\n",
      "    for ref_seq in Bio.SeqIO.parse(ref_handle, \"fasta\"): # iterate through the all (in this case one) seqs in the fasta file\n",
      "        ref_frag_seqs = Bio.Restriction.SwaI.catalyze(ref_seq.seq) # split that seqence into a tuple of sequences\n",
      "    \n",
      "print(ref_frag_seqs[:2]) # print the first two fragments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(Seq('AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAG...TTT', SingleLetterAlphabet()), Seq('AAATTAAAATCCATCTTTCAACCTCTTGATATTTTGGGGGTTAATTAATCTTTC...TTT', SingleLetterAlphabet()))\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.seed(8675309) # initialize this to a \"random\" number so this notebook is reproducible\n",
      "\n",
      "def noise(lst, small_cutoff, stddev):\n",
      "    return [int(random.gauss(0, stddev)) + s for s in lst if s >= small_cutoff]\n",
      "\n",
      "ref_frag_lengths = [len(ref_frag) for ref_frag in ref_frag_seqs]\n",
      "noisy_frags = noise(ref_frag_lengths, small_cutoff=700, stddev=150)\n",
      "\n",
      "print(noisy_frags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[40226, 81532, 122840, 1194, 50221, 19636, 27276, 57108, 33243, 2605, 107188, 25540, 15351, 42488, 81284, 141588, 50132, 28308, 57921, 10670, 50153, 17596, 115609, 30380, 8532, 31972, 6119, 33543, 21278, 46756, 31057, 26520, 15478, 69668, 88918, 5889, 2709, 18869, 3227, 9980, 5752, 7733, 36140, 29378, 9736, 90791, 7930, 94844, 2194, 39616, 9094, 34753, 5255, 98464, 101786, 51787, 17789, 29444, 77084, 40071, 31578, 19094, 4456, 4226, 1239, 28256, 203819, 57944, 21107, 65100, 7656, 175914, 75772, 15125, 99637, 29570, 11774, 45392, 41521, 184441, 111685, 9905, 104362, 25395, 17475, 13946, 61524, 8200, 733, 12159, 36378, 3281, 28732, 73220, 8003, 2200, 6392, 8888, 14466, 87525, 41859, 13379, 15020, 63761, 34057, 71288, 55396, 761, 7451, 55237, 40286, 39667, 22059]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_frags(fname, frags):\n",
      "    with open(fname, \"w\") as om:\n",
      "        for frag in frags:\n",
      "            # SOMA format uses frag sizes in kb, we don't per frag stddev, so use 0.0\n",
      "            line = str(frag/1000.0) + \"\\t\" + str(0.0) + \"\\n\"\n",
      "            om.write(line) \n",
      "\n",
      "write_frags(\"ecoli_optmap\", noisy_frags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1+2 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ls -l ecoli_optmap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw------- 1 darshanw grad 1207 Dec 17 17:16 ecoli_optmap\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interior_end_points = [random.randint(0, len(ref_seq)) for i in range(9)]\n",
      "end_points = [0] + interior_end_points + [len(ref_seq)]\n",
      "end_points.sort()\n",
      "\n",
      "print(end_points)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 656470, 1160129, 1236731, 1366606, 1573538, 2173411, 2430032, 4351221, 4541002, 4639675]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contig_loci = {} # bookkeeping to see how clone the TWIN alignments with accumulated restriction fragment based locus match\n",
      "\n",
      "with open(\"fake_contigs.fa\", \"w\") as contigs_handle:\n",
      "    for interval_num, (start, end) in enumerate(zip(end_points, end_points[1:])):\n",
      "        subseq = ref_seq[start:end]\n",
      "        if random.randint(0,1) == 0:  # reverse complement with 50% probability\n",
      "            subseq.reverse_complement()\n",
      "        print( len(subseq))\n",
      "        subseq.id = \"fake_contig_\" + str(interval_num)\n",
      "        contig_loci[subseq.id] = start\n",
      "        Bio.SeqIO.write(subseq, contigs_handle, \"fasta\")\n",
      "        \n",
      "\n",
      "! grep -n \"^>\" fake_contigs.f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "656470\n",
        "503659\n",
        "76602"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "129875\n",
        "206932\n",
        "599873\n",
        "256621\n",
        "1921189"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "189781"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "98673\n",
        "grep: fake_contigs.f: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"fake_contigs.fa\") as f:\n",
      "    for s in Bio.SeqIO.parse( f, \"fasta\"):\n",
      "        print(len(s))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "656470\n",
        "503659\n",
        "76602\n",
        "129875\n",
        "206932\n",
        "599873"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "256621\n",
        "1921189"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "189781\n",
        "98673\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ~/twin/digest.py fake_contigs.fa SwaI  fake_contigs.silico\n",
      "\n",
      "! ls -l fake_contigs*\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/bin/sh: /s/chopin/a/grad/darshanw/twin/digest.py: No such file or directory\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw------- 1 darshanw grad 4717958 Dec 22 21:54 fake_contigs.fa\r\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}